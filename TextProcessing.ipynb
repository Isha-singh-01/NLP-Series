{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86194d8-30f2-4448-963b-96dda2207d1f",
   "metadata": {},
   "source": [
    "# Text Processing Techniques in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ea92f-326a-4092-b249-fb8c3cad4b5e",
   "metadata": {},
   "source": [
    "In this notebook, I have performed various text processing techniques that are important in NLP and before we begin any analysis/model building. Some of the techniques are:\n",
    "1) Lowercasing\n",
    "2) Removing html tags\n",
    "3) Removing punctuations\n",
    "4) Removing urls\n",
    "5) Dealing with short forms\n",
    "6) Spelling corrections\n",
    "7) Removing stop-words\n",
    "8) Tokenization\n",
    "9) Stemming\n",
    "10) Lemmatization\n",
    "\n",
    "All these techniques are discussed in depth and with suitable examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b49b2-7d43-4cb9-8a3b-89c2387e7990",
   "metadata": {},
   "source": [
    "### 1) Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502c1131-a280-4e39-8889-9777c0076757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33644e4-23a0-4b35-9795-f48736c66296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e043ca49-d1b7-4f82-9562-bad2bdcf5b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the dataset consists of two columns: review and sentiment\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0253ce-84dc-4a4a-b437-c69b35151fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9645b-ab81-4d34-a63f-b3e084f494f4",
   "metadata": {},
   "source": [
    "### 2) Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bded4a57-f0dd-4abc-a925-2eac77368d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production. <br /><br />the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master\\'s of comedy and his life. <br /><br />the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['review'][1]\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3d5a2f-d7e3-469c-bc09-987b1eb53a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51018575-c91c-40a6-a6b7-d533d436f57f",
   "metadata": {},
   "source": [
    "### 3) Removing html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4743e7-9531-492b-96cf-e80a7504b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTags(text):\n",
    "    pattern = '<.*?>'\n",
    "    return re.sub(pattern,'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7579426d-0a12-4d31-85f3-7aec8eb796b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production. the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master\\'s of comedy and his life. the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(removeTags)\n",
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d6d0cc-8788-4c99-8ce6-d96265757552",
   "metadata": {},
   "source": [
    "### 4) Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b53feaf-d0ac-4f18-9dbd-f6c4d7b42b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b56133ac-95c8-44dd-8488-f19de07eee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePuncs(text):\n",
    "    puncs = string.punctuation\n",
    "    for char in puncs:\n",
    "        text = text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b3b229-68e0-46d4-9b30-4fc4d3532e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(removePuncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7af063ea-10e3-4fe5-987e-f0b3436490de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A much faster way to remove punctuations\n",
    "def removePuncs1(text):\n",
    "    return text.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12a336-848e-4fa6-bb73-cacf30e44408",
   "metadata": {},
   "source": [
    "### 5) Removing urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca892575-e4e5-4759-9a2e-abe964f7af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUrls(text):\n",
    "    pattern = 'https?://\\S+|www\\.\\S+' #S+ represents any non-whitespace character (one or more occurences)\n",
    "    return re.sub(pattern,'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "349468c6-51f0-4ee4-811c-fdc205cf2926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sample website with the following urls: fb ( instagram ( google ( end of text.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'This is a sample website with the following urls: fb (https://facebook.com), instagram (http://instagram.com), google (www.google.com) end of text.'\n",
    "removeUrls(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74adf60e-e9e7-41db-93a7-7702fa986a41",
   "metadata": {},
   "source": [
    "### 6) Dealing with short forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb86b60-251d-49b7-9a3f-86a4afd42bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('slang.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "    slangs = {}\n",
    "    for line in lines:\n",
    "        abbs, meaning = line.strip().split('=')\n",
    "        slangs[abbs] = meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40577b0-a4c4-4d11-be2e-d950518486c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFAIK': 'As Far As I Know',\n",
       " 'AFK': 'Away From Keyboard',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'ATK': 'At The Keyboard',\n",
       " 'ATM': 'At The Moment',\n",
       " 'A3': 'Anytime, Anywhere, Anyplace',\n",
       " 'BAK': 'Back At Keyboard',\n",
       " 'BBL': 'Be Back Later',\n",
       " 'BBS': 'Be Back Soon',\n",
       " 'BFN': 'Bye For Now',\n",
       " 'B4N': 'Bye For Now',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BRT': 'Be Right There',\n",
       " 'BTW': 'By The Way',\n",
       " 'B4': 'Before',\n",
       " 'CU': 'See You',\n",
       " 'CUL8R': 'See You Later',\n",
       " 'CYA': 'See You',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'FC': 'Fingers Crossed',\n",
       " 'FWIW': \"For What It's Worth\",\n",
       " 'FYI': 'For Your Information',\n",
       " 'GAL': 'Get A Life',\n",
       " 'GG': 'Good Game',\n",
       " 'GN': 'Good Night',\n",
       " 'GMTA': 'Great Minds Think Alike',\n",
       " 'GR8': 'Great!',\n",
       " 'G9': 'Genius',\n",
       " 'IC': 'I See',\n",
       " 'ICQ': 'I Seek you (also a chat program)',\n",
       " 'ILU': 'ILU: I Love You',\n",
       " 'IMHO': 'In My Honest/Humble Opinion',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'IOW': 'In Other Words',\n",
       " 'IRL': 'In Real Life',\n",
       " 'KISS': 'Keep It Simple, Stupid',\n",
       " 'LDR': 'Long Distance Relationship',\n",
       " 'LMAO': 'Laugh My A.. Off',\n",
       " 'LOL': 'Laughing Out Loud',\n",
       " 'LTNS': 'Long Time No See',\n",
       " 'L8R': 'Later',\n",
       " 'MTE': 'My Thoughts Exactly',\n",
       " 'M8': 'Mate',\n",
       " 'NRN': 'No Reply Necessary',\n",
       " 'OIC': 'Oh I See',\n",
       " 'PITA': 'Pain In The A..',\n",
       " 'PRT': 'Party',\n",
       " 'PRW': 'Parents Are Watching',\n",
       " 'ROFL': 'Rolling On The Floor Laughing',\n",
       " 'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
       " 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
       " 'SK8': 'Skate',\n",
       " 'STATS': 'Your sex and age',\n",
       " 'ASL': 'Age, Sex, Location',\n",
       " 'THX': 'Thank You',\n",
       " 'TTFN': 'Ta-Ta For Now!',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'U': 'You',\n",
       " 'U2': 'You Too',\n",
       " 'U4E': 'Yours For Ever',\n",
       " 'WB': 'Welcome Back',\n",
       " 'WTF': 'What The F...',\n",
       " 'WTG': 'Way To Go!',\n",
       " 'WUF': 'Where Are You From?',\n",
       " 'W8': 'Wait...',\n",
       " '7K': 'Sick:-D Laugher',\n",
       " 'TFW ': ' That feeling when. TFW internet slang often goes in a caption to an image.',\n",
       " 'MFW ': ' My face when',\n",
       " 'MRW ': ' My reaction when',\n",
       " 'IFYP ': ' I feel your pain',\n",
       " 'LOL ': ' Laughing out loud',\n",
       " 'TNTL ': ' Trying not to laugh',\n",
       " 'JK ': ' Just kidding',\n",
       " 'IDC ': ' I donâ€™t care',\n",
       " 'ILY ': ' I love you',\n",
       " 'IMU ': ' I miss you',\n",
       " 'ADIH ': ' Another day in hell',\n",
       " 'ZZZ ': ' Sleeping, bored, tired',\n",
       " 'WYWH ': ' Wish you were here',\n",
       " 'TIME ': ' Tears in my eyes',\n",
       " 'BAE ': ' Before anyone else',\n",
       " 'FIMH ': ' Forever in my heart',\n",
       " 'BSAAW ': ' Big smile and a wink',\n",
       " 'BWL ': ' Bursting with laughter',\n",
       " 'LMAO ': ' Laughing my a** off',\n",
       " 'BFF': ' Best friends forever',\n",
       " 'CSL ': ' Canâ€™t stop laughing'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153f051c-8cbd-46ca-a567-d005b0d7f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'FYI: This position is only for graduates. Please apply ASAP. Have a GR8 day ahead! '\n",
    "def shortForms(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word.upper() in slangs:\n",
    "            new_text.append(slangs[word.upper()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82630a7c-b068-463f-9b1a-9da1682e68d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For Your Information This position is only for graduates Please apply As Soon As Possible Have a Great! day ahead'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = removePuncs1(text) #first remove all the punctuations\n",
    "shortForms(text) #complete the short forms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01467e8-2ea8-40d1-ab57-f81f00b24600",
   "metadata": {},
   "source": [
    "### 7) Spelling corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54c6e18e-7bbf-41c5-9e78-510b21721a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc843c02-b145-4994-8227-0d3d9701ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = 'This text contains sveral spelling errorrs.'\n",
    "blob = TextBlob(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d27aed7-b424-454a-a2f1-4a2c501711ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'His text contains several spelling errors.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e5d24-897e-4610-9304-c8fcc772dadd",
   "metadata": {},
   "source": [
    "### 8) Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caf2804b-1f9f-4701-8f0d-6347473322ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ishas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37022ef1-7fef-472d-9d2c-aed3f5f83010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5caeed7-0361-4eeb-9361-9fd10e8922c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    newtext = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            newtext.append('')\n",
    "        else:\n",
    "            newtext.append(word)\n",
    "    return ' '.join(newtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7109e2e2-ad7d-476f-aeb1-3e1e15e1836c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' wonderful little production  filming technique   unassuming  oldtimebbc fashion  gives  comforting  sometimes discomforting sense  realism   entire piece  actors  extremely well chosen michael sheen    got   polari      voices  pat    truly see  seamless editing guided   references  williams diary entries     well worth  watching     terrificly written  performed piece  masterful production  one   great masters  comedy   life  realism really comes home   little things  fantasy   guard  rather  use  traditional dream techniques remains solid  disappears  plays   knowledge   senses particularly   scenes concerning orton  halliwell   sets particularly   flat  halliwells murals decorating every surface  terribly well done'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['review'][1]\n",
    "remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd4847-c249-47e3-a787-181185217b6d",
   "metadata": {},
   "source": [
    "### 9) Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "455b2435-ccb2-4144-829c-0446cd86456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f43b8358-87a5-4628-887a-6cd45e6a2dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am going to delhi! I'll be late\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I am going to delhi! I'll be late\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9fc3f7-99d2-4be2-a468-9c45064d30f4",
   "metadata": {},
   "source": [
    "**Using split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed2c99b2-8f51-4b21-ad1f-6390459a5404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word tokenization: ['I', 'am', 'going', 'to', 'delhi!', \"I'll\", 'be', 'late']\n",
      "Sentence tokenization: [\"I am going to delhi! I'll be late\"]\n"
     ]
    }
   ],
   "source": [
    "words = text.split()\n",
    "sentences = text.split('.')\n",
    "print('Word tokenization:',words)\n",
    "print('Sentence tokenization:',sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f98c48-e116-4376-bd64-4658ca8e023a",
   "metadata": {},
   "source": [
    "**Using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e26beed-890b-472b-a7fc-37084bed1775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi', '!', 'I', \"'ll\", 'be', 'late']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e09c1bb-a764-4913-8d45-43554be99f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi!', \"I'll be late\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text) #it separated the sentence based on exclamation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8841279-24dc-477e-be7e-307df46e024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence tokenization: ['I have a Ph.D. in A.I.']\n",
      "Word tokenization: ['I', 'have', 'a', 'Ph.D.', 'in', 'A.I', '.']\n"
     ]
    }
   ],
   "source": [
    "sent = 'I have a Ph.D. in A.I.'\n",
    "print(\"Sentence tokenization:\",sent_tokenize(sent))\n",
    "print(\"Word tokenization:\",word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd57a20-4166-445e-815d-ab41c6889691",
   "metadata": {},
   "source": [
    "**Using Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c368e7-9897-4bd4-a9b3-4890d7add4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4f275a-4b2c-4a31-83a0-c0d02db12c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves burger.\n",
      "Hulk loves ham.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp('Dr. Strange loves burger. Hulk loves ham.')\n",
    "for i in doc.sents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59b3e59d-6127-4bf3-ae25-18dead121c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "number\n",
      "two\n",
      "at\n",
      "$\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('This is number two at $4')\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fda8090-ae64-4bfa-97fd-27617d512e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.', 'Strange loves burger.', 'Hulk loves ham.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize('Dr. Strange loves burger. Hulk loves ham.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f7fe2-5cbf-4fad-9f41-ead8ad8902ea",
   "metadata": {},
   "source": [
    "**Some methods of spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec2aef3-33db-45d1-bb98-99c4b5230119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(two, True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3],doc[3].like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7daed712-01ba-4999-9833-9b98a70b8317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "($, True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[5],doc[5].is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad799ba8-832b-4966-830c-866002279bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dayton high school, 8th grade students information\\n',\n",
       " '==================================================\\n',\n",
       " '\\n',\n",
       " 'Name\\tbirth day   \\temail\\n',\n",
       " '-----\\t------------\\t------\\n',\n",
       " 'Virat   5 June, 1882    virat@kohli.com\\n',\n",
       " 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n",
       " 'Serena  24 June, 1998   serena@williams.com \\n',\n",
       " 'Joe      1 May, 1997    joe@root.com\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('students.txt') as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "089157c7-7de8-4946-9507-df73067de9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com\\n \\n \\n \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b8b57ec-a29f-4078-8422-f87ca07ed351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[virat@kohli.com, maria@sharapova.com, serena@williams.com, joe@root.com]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nlp(text)\n",
    "emails = []\n",
    "for token in text:\n",
    "    if token.like_email:\n",
    "        emails.append(token)\n",
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c808e2c3-3fb6-4006-bec8-026cf0e44406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc] #.text to convert into string\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5119f2e-9627-4e6b-9722-c37c65447946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.data.gov/',\n",
       " 'http://www.science',\n",
       " 'http://data.gov.uk/.',\n",
       " 'http://www3.norc.org/gss+website/',\n",
       " 'http://www.europeansocialsurvey.org/.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''\n",
    "\n",
    "# TODO: Write code here\n",
    "# Hint: token has an attribute that can be used to detect a url\n",
    "doc = nlp(text)\n",
    "urls = [token.text for token in doc if token.like_url]\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "143cbfe4-9e2d-4be4-8162-5f7a2579852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "#Extract all money transaction from below sentence along with currency. Output should be,two $ 500 €\n",
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "doc = nlp(transactions)\n",
    "for token in doc:\n",
    "    if token.like_num and doc[token.i+1].is_currency:\n",
    "        print(token.text, doc[token.i+1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023da13e-006a-4b19-b1d2-d33c4c742f7d",
   "metadata": {},
   "source": [
    "### 9) Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039b474-d5cd-4a2a-9ab7-670673d85ab6",
   "metadata": {},
   "source": [
    " Inflection is a modification of a word to express different grammatical categories such as tence, case,voice, gender, mood etc. Stemming is the process of removing inflection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0a6b5ff-62cf-48d5-a7b6-2723f280cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c99468d0-a3b2-4bee-9ccc-58b4abf7ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "ls = LancasterStemmer()\n",
    "ss = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0146cf7-1a7a-4fcd-a37f-ad2eca3a9e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danc dancer danc danc --> Using porter\n",
      "dant dant dant dant --> Using lancester\n",
      "danc dancer danc danc --> Using snowball\n"
     ]
    }
   ],
   "source": [
    "sample = 'dance dancer dances dancing'\n",
    "print(\" \".join([ps.stem(word) for word in sample.split()]),\"--> Using porter\")\n",
    "print(\" \".join([ls.stem(word) for word in sample.split()]),\"--> Using lancester\")\n",
    "print(\" \".join([ss.stem(word) for word in sample.split()]),\"--> Using snowball\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e3d8bec-594b-4330-82e8-dab98298638b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonder littl product the film techniqu is veri unassum veri oldtimebbc fashion and give a comfort and sometim discomfort sens of realism to the entir piec the actor are extrem well chosen michael sheen not onli ha got all the polari but he ha all the voic down pat too you can truli see the seamless edit guid by the refer to william diari entri not onli is it well worth the watch but it is a terrificli written and perform piec a master product about one of the great master of comedi and hi life the realism realli come home with the littl thing the fantasi of the guard which rather than use the tradit dream techniqu remain solid then disappear it play on our knowledg and our sens particularli with the scene concern orton and halliwel and the set particularli of their flat with halliwel mural decor everi surfac are terribl well done'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['review'][1]\n",
    "\" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be9750-0289-4e34-a2e1-d61e568601d2",
   "metadata": {},
   "source": [
    "**The words modified by stemming may/may not be english words. That's why we need lemmatization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e550b7aa-4a97-4035-b9a0-5004124afa70",
   "metadata": {},
   "source": [
    "### 10) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14295c72-d4d2-4e59-bf0b-c77aeaee7545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ishas\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2388946c-adbb-4321-93cb-36e62503ec49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'was',\n",
       " 'running',\n",
       " 'while',\n",
       " 'eating',\n",
       " 'He',\n",
       " 'has',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'watching',\n",
       " 'his',\n",
       " 'phone',\n",
       " 'at',\n",
       " 'night']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"He was running while eating. He has a bad habit of watching his phone at night!\"\n",
    "puncs = string.punctuation\n",
    "words = word_tokenize(sample)\n",
    "for word in words:\n",
    "    if word in puncs:\n",
    "       words.remove(word)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3edb0202-f164-4de5-aaab-7127ef8ebb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "was                 be                  \n",
      "running             run                 \n",
      "while               while               \n",
      "eating              eat                 \n",
      "He                  He                  \n",
      "has                 have                \n",
      "a                   a                   \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "watching            watch               \n",
      "his                 his                 \n",
      "phone               phone               \n",
      "at                  at                  \n",
      "night               night               \n"
     ]
    }
   ],
   "source": [
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in words:\n",
    "    print(\"{0:20}{1:20}\".format(word,lemm.lemmatize(word,pos='v'))) #pos = v (for verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43d31d-b0e4-4953-bb97-ba0040aea1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
