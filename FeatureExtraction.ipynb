{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8e522a-e2dc-4304-b498-4428c78d24bd",
   "metadata": {},
   "source": [
    "## Feature Extraction\r\n",
    "\r\n",
    "This notebook discusses the various methods of feature extraction. It is also known as Text Vectorization or text representation. This technique is used to convert the words into vectors so that they can be used for modeling. The various techniques are as following of semantic meaning.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f22ab2-1793-438c-8e83-22d70dfebe8d",
   "metadata": {},
   "source": [
    "### 1. One hot encoding: \n",
    "\n",
    "Most basic technique to convert words into vectors. Consider the following example.\n",
    "- Doc1 = \"It is raining\"\n",
    "- Doc2 = \"Boston is raining\"\n",
    "- Doc3 = \"Rain raining everywhere.\"\n",
    "\n",
    "Vocabulary of this corpus = [\"It\",\"is\",\"raining\",\"Boston\",\"rain\",\"everywhere\"].\n",
    "In the vector form these docs can be converted as:\n",
    "    \n",
    "```\n",
    "Doc1 = [[1,0,0,0,0,0],[0,1,0,0,0,0],[0,0,1,0,0,0]] -- size of this vector is 3X6.\n",
    "Doc2 = [[0,0,0,1,0,0],[0,1,0,0,0,0],[0,0,1,0,0,0]] -- size of this vector is 3X6.\n",
    "```\n",
    "\n",
    "In general, each word of each document is converted to a vector.\n",
    "\n",
    "**Pros:** \n",
    "- Very simple, intuitive, easy to implement.\n",
    "    \n",
    "**Cons:** \n",
    "- Sparsity, different array sizes won't work, out of vocabulary words will throw an error, no capturing of semantic meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb44cc1-d8c3-4fe4-b81c-e4f1cea5421a",
   "metadata": {},
   "source": [
    "### 2. Bag of Words:\n",
    "It deals with occurence of words in a document.\n",
    "\n",
    "- Doc1 = \"The more the merrier.\"\n",
    "- Doc2 = \"More people enrolled\"\n",
    "- Doc3 = \"Enrolled last week\"\n",
    "\n",
    "Vocabulary of this corpus = [\"The\",\"more\",\"merrier\",\"peope\",\"enrolled\",\"last\",\"week\"].\n",
    "In the vector form these docs can be converted as:\n",
    "    \n",
    "```\n",
    "Doc1 = [2,1,1,0,0,0,0]\n",
    "Doc2 = [0,1,0,1,1,0,0]\n",
    "Doc3 = [0,0,0,0,1,1,1]\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- Simple and easy to understand, No fixed size required, doesn't throw an error for out of vocabulary words, captures semantic meaning (less)\n",
    "\n",
    "**Cons:**\n",
    "- Ignores new words in the text dataset.\n",
    "- Sparsity\n",
    "- Consider: \"This is a good book\" and \"This is not a good book\". Because the docs contain same words at same frequency, this approach treats the two documents as similar, when in reality they convey opposite meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb91dd6-c9a2-40cf-9fa3-b80609eeed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675af4b4-59ba-42e9-a765-2e3e343e2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'documents':[\"The more the merrier.\",\"More people enrolled\",\"Enrolled last week\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e680bb0f-7347-4082-9b7e-f5b48779b714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The more the merrier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>More people enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enrolled last week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               documents\n",
       "0  The more the merrier.\n",
       "1   More people enrolled\n",
       "2     Enrolled last week"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93221d1-78cf-451e-bb55-d8d23573f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bb6207a-cbbd-46a8-9f8d-bae3ddfd759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cv.fit_transform(df['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad336277-221d-40a3-9883-aea8ed9eea25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 5,\n",
       " 'more': 3,\n",
       " 'merrier': 2,\n",
       " 'people': 4,\n",
       " 'enrolled': 0,\n",
       " 'last': 1,\n",
       " 'week': 6}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vocabulary\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb12bfc-548b-4b46-bd64-adc6f0861204",
   "metadata": {},
   "source": [
    "The numbers indicate their ordering index. These words are alphabetically ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de5e9ca0-0e49-4111-8f54-af82cc8d2bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector form of doc1: [[0 0 1 1 0 2 0]]\n",
      "Vector form of doc2: [[1 0 0 1 1 0 0]]\n",
      "Vector form of doc3: [[1 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector form of doc1:\",bow[0].toarray())\n",
    "print(\"Vector form of doc2:\",bow[1].toarray())\n",
    "print(\"Vector form of doc3:\",bow[2].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ed3cd4-7b85-43ea-b895-ae3193d13793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(['This sentence contains more words']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7e5ff-5199-4ed1-891c-1cbbf18f9f11",
   "metadata": {},
   "source": [
    "As expected the new words got ignored in the vector form; one of the drawback of BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321c0d2-beb9-4036-ad16-03dfbd726b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
